{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext.data as ttd\n",
    "from torchtext.vocab import GloVe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Opinion, &amp;#124;, Glenn, Youngkin, ’, s, No-Gu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Opinion, &amp;#124;, Glenn, Youngkin, ’, s, No-Gu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Won, ', t, be, long, ,, and, they, ', ll, be,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Federal, Standards, for, education, are, need...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[They, don, ', t, want, to, be, made, uncomfor...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28121</th>\n",
       "      <td>[Remember, when, talking, about, covid, or, th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28122</th>\n",
       "      <td>[When, the, science, changes, to, match, the, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28123</th>\n",
       "      <td>[I, personally, can, ', t, wait, for, covid, t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28124</th>\n",
       "      <td>[I, keep, seeing, people, say, this, but, what...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28125</th>\n",
       "      <td>[If, they, had, given, mRNA, “vaccines, ”, mor...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  classification\n",
       "0      [Opinion, &#124;, Glenn, Youngkin, ’, s, No-Gu...             0.0\n",
       "1      [Opinion, &#124;, Glenn, Youngkin, ’, s, No-Gu...             0.0\n",
       "2      [Won, ', t, be, long, ,, and, they, ', ll, be,...             0.0\n",
       "3      [Federal, Standards, for, education, are, need...             0.0\n",
       "4      [They, don, ', t, want, to, be, made, uncomfor...             0.0\n",
       "...                                                  ...             ...\n",
       "28121  [Remember, when, talking, about, covid, or, th...             1.0\n",
       "28122  [When, the, science, changes, to, match, the, ...             1.0\n",
       "28123  [I, personally, can, ', t, wait, for, covid, t...             1.0\n",
       "28124  [I, keep, seeing, people, say, this, but, what...             1.0\n",
       "28125  [If, they, had, given, mRNA, “vaccines, ”, mor...             1.0\n",
       "\n",
       "[28126 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_finalized.csv\",index_col=0)\n",
    "df['classification'] = df['classification'].map({'left': 0, 'right': 1})\n",
    "tonkenized_df = pd.DataFrame()\n",
    "tokenizer = ttd.utils.get_tokenizer(\"toktok\")\n",
    "for index , row in df.iterrows(): \n",
    "    js = {\n",
    "        \"text\": tokenizer(row[\"text\"]),\n",
    "        \"classification\": row[\"classification\"]\n",
    "    }\n",
    "    tonkenized_df = tonkenized_df.append(js,ignore_index = True)\n",
    "\n",
    "tonkenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Opinion, &#124;, Glenn, Youngkin, ’, s, No-Gu...\n",
       "1        [Opinion, &#124;, Glenn, Youngkin, ’, s, No-Gu...\n",
       "2        [Won, ', t, be, long, ,, and, they, ', ll, be,...\n",
       "3        [Federal, Standards, for, education, are, need...\n",
       "4        [They, don, ', t, want, to, be, made, uncomfor...\n",
       "                               ...                        \n",
       "28121    [Remember, when, talking, about, covid, or, th...\n",
       "28122    [When, the, science, changes, to, match, the, ...\n",
       "28123    [I, personally, can, ', t, wait, for, covid, t...\n",
       "28124    [I, keep, seeing, people, say, this, but, what...\n",
       "28125    [If, they, had, given, mRNA, “vaccines, ”, mor...\n",
       "Name: text, Length: 28126, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tonkenized_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.000e+00, 0.000e+00, 5.000e+00, 1.000e+01, 2.500e+01, 2.500e+01,\n",
       "        4.200e+01, 9.700e+01, 3.540e+02, 8.790e+02, 1.059e+03, 1.372e+03,\n",
       "        1.346e+03, 1.327e+03, 1.245e+03, 1.273e+03, 1.111e+03, 1.047e+03,\n",
       "        9.800e+02, 9.040e+02, 8.380e+02, 7.890e+02, 7.260e+02, 6.690e+02,\n",
       "        6.300e+02, 5.910e+02, 5.980e+02, 5.350e+02, 4.840e+02, 4.560e+02,\n",
       "        4.380e+02, 4.080e+02, 3.680e+02, 4.590e+02, 3.150e+02, 3.160e+02,\n",
       "        3.030e+02, 2.760e+02, 3.090e+02, 2.480e+02, 2.430e+02, 2.300e+02,\n",
       "        2.380e+02, 2.090e+02, 1.870e+02, 1.620e+02, 1.860e+02, 1.610e+02,\n",
       "        1.680e+02, 1.390e+02, 1.220e+02, 1.410e+02, 1.420e+02, 1.300e+02,\n",
       "        1.210e+02, 1.040e+02, 1.100e+02, 1.140e+02, 7.800e+01, 1.090e+02,\n",
       "        1.020e+02, 8.000e+01, 7.400e+01, 7.100e+01, 8.000e+01, 8.200e+01,\n",
       "        5.700e+01, 7.100e+01, 6.400e+01, 6.400e+01, 5.600e+01, 5.900e+01,\n",
       "        4.700e+01, 5.400e+01, 4.100e+01, 4.400e+01, 4.200e+01, 6.000e+01,\n",
       "        3.900e+01, 3.200e+01, 2.500e+01, 3.400e+01, 2.700e+01, 2.400e+01,\n",
       "        2.900e+01, 2.700e+01, 2.800e+01, 2.100e+01, 2.700e+01, 3.200e+01,\n",
       "        3.000e+01, 2.300e+01, 2.200e+01, 1.800e+01, 2.300e+01, 1.400e+01,\n",
       "        2.000e+01, 2.000e+01, 2.200e+01, 2.300e+01, 1.700e+01, 1.500e+01,\n",
       "        1.000e+01, 1.100e+01, 1.300e+01, 1.100e+01, 9.000e+00, 7.000e+00,\n",
       "        1.500e+01, 1.500e+01, 1.600e+01, 7.000e+00, 1.200e+01, 1.200e+01,\n",
       "        7.000e+00, 1.000e+01, 6.000e+00, 6.000e+00, 7.000e+00, 1.000e+01,\n",
       "        8.000e+00, 7.000e+00, 5.000e+00, 7.000e+00, 8.000e+00, 1.000e+00,\n",
       "        1.000e+00, 6.000e+00, 6.000e+00, 6.000e+00, 6.000e+00, 1.000e+01,\n",
       "        4.000e+00, 4.000e+00, 7.000e+00, 4.000e+00, 4.000e+00, 3.000e+00,\n",
       "        2.000e+00, 2.000e+00, 6.000e+00, 2.000e+00, 4.000e+00, 3.000e+00,\n",
       "        5.000e+00, 5.000e+00, 5.000e+00, 4.000e+00, 2.000e+00, 5.000e+00,\n",
       "        1.000e+00, 2.000e+00, 5.000e+00, 2.000e+00, 2.000e+00, 1.000e+00,\n",
       "        5.000e+00, 2.000e+00, 4.000e+00, 3.000e+00, 3.000e+00, 2.000e+00,\n",
       "        3.000e+00, 4.000e+00, 3.000e+00, 2.000e+00, 1.000e+00, 2.000e+00,\n",
       "        1.000e+00, 2.000e+00, 1.000e+00, 3.000e+00, 4.000e+00, 1.000e+00,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "        2.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 3.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 2.000e+00,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199]),\n",
       " <BarContainer object of 199 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length  = []\n",
    "for text in tonkenized_df[\"text\"]:\n",
    "    length.append(len(text))\n",
    "plt.hist(length,bins=np.arange(0, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-5.5814e-01,  7.3198e-01, -1.4123e-01,  7.0702e-01, -4.3387e-01,\n",
       "         -2.8708e-01, -4.6091e-01,  1.7632e+00,  6.6918e-02, -5.2153e-01,\n",
       "         -4.1592e-01, -7.0236e-01, -3.0633e+00, -6.0575e-02,  7.0095e-01,\n",
       "         -1.0135e-01,  7.2264e-01,  5.9836e-02, -5.2989e-02, -1.9694e-01,\n",
       "          7.7576e-01,  5.6437e-01, -1.3116e-03,  5.0619e-02,  2.8799e-01],\n",
       "        [ 4.4205e-01, -6.7697e-01, -7.9938e-02,  8.9579e-01, -4.3245e-02,\n",
       "          3.5863e-01,  5.1735e-01,  1.4330e+00, -2.1658e-01,  9.3923e-01,\n",
       "          3.6207e-01, -2.7295e-01, -3.4128e+00,  4.6583e-01, -8.7769e-01,\n",
       "         -4.2464e-01, -1.3648e+00,  4.3996e-01, -2.4477e+00, -2.3733e-01,\n",
       "          4.2426e-01,  1.8637e-01, -1.9753e-01,  2.6109e-01,  4.4809e-01],\n",
       "        [ 7.8637e-01,  1.4593e-01, -1.2834e+00, -8.2192e-02, -6.2889e-01,\n",
       "          5.2688e-01, -1.8855e-01,  2.0070e+00, -1.8195e-01, -2.9286e-02,\n",
       "         -5.9935e-01, -3.5501e-01, -3.7720e+00,  3.8563e-01, -6.7084e-01,\n",
       "          3.0003e-01, -6.5916e-01,  2.1904e-01, -1.6913e+00,  1.4055e+00,\n",
       "          9.0167e-02, -9.4622e-01,  5.8861e-01,  5.8052e-01,  4.7455e-02],\n",
       "        [ 2.0361e-01,  8.3128e-01, -6.4653e-01, -3.0887e-01, -1.0572e+00,\n",
       "         -7.1749e-02,  1.2202e+00, -3.9147e-01, -1.1778e+00, -1.4753e-01,\n",
       "         -9.9243e-02,  4.5723e-01, -5.4946e+00, -1.1159e+00, -8.5669e-01,\n",
       "          5.0354e-01,  6.7783e-01, -5.1673e-01, -2.0734e-01,  6.6540e-05,\n",
       "         -1.9598e-01,  2.8344e-01,  2.6416e-02,  6.4498e-01,  2.0046e-01],\n",
       "        [ 2.8228e-01,  1.9558e-02,  1.1509e-01, -3.9242e-01, -1.0503e+00,\n",
       "         -5.4278e-01,  1.1357e+00, -3.4251e-01,  8.0636e-01, -4.7359e-01,\n",
       "         -7.7194e-01, -7.3689e-01, -6.2619e+00, -3.4902e-01, -3.5532e-01,\n",
       "         -6.0148e-01, -5.4534e-02, -6.7057e-01, -3.9972e-01, -1.3240e+00,\n",
       "         -4.3765e-01,  3.0045e-01,  2.1430e-01,  2.5422e-01, -2.6674e-01],\n",
       "        [-3.4350e-01,  1.0138e+00, -3.9231e-02, -6.1739e-01, -1.3000e-01,\n",
       "          6.5973e-01,  1.1861e+00, -1.1700e-01, -6.1421e-01,  3.9945e-01,\n",
       "         -3.3834e-01,  5.4643e-01, -5.4199e+00,  3.1714e-01, -6.2972e-01,\n",
       "         -4.9683e-01,  3.8104e-01, -5.2959e-01, -5.1274e-01, -8.8274e-01,\n",
       "          5.2400e-01,  1.0320e+00, -6.2416e-01,  1.2028e-01, -1.0696e-01],\n",
       "        [-1.9036e-01,  6.1504e-02,  3.5300e-01, -1.3775e-01, -1.2903e-01,\n",
       "          5.1283e-02,  1.4205e+00, -4.5554e-01, -7.6075e-01, -1.9004e-01,\n",
       "          6.9336e-01,  5.7795e-01, -4.7920e+00, -4.6092e-01, -2.0459e-03,\n",
       "         -9.9666e-02,  8.1420e-01, -4.1994e-01, -2.3572e-02, -2.6787e-01,\n",
       "         -1.0993e-01,  3.4116e-01, -2.3105e-01,  2.8249e-01,  7.8486e-02],\n",
       "        [-7.9550e-01, -1.2109e+00,  6.4386e-02, -2.2949e-01,  6.6359e-01,\n",
       "          1.4209e+00,  1.1066e+00, -1.7104e+00, -5.6174e-01,  2.1702e-01,\n",
       "         -1.1904e+00,  1.3708e-01, -2.5683e+00, -1.4728e-01,  1.0497e-01,\n",
       "          1.1528e+00, -1.2369e-01, -3.6032e-01,  9.2831e-02, -1.1332e+00,\n",
       "          5.9174e-01,  3.6326e-01,  1.2790e-01, -1.3790e-01, -1.2326e+00],\n",
       "        [-4.7133e-01, -3.3320e-01,  1.5431e-01,  6.7052e-01, -1.2519e-01,\n",
       "         -3.4317e-01,  6.6931e-01,  5.8622e-01,  2.2084e-01, -2.3087e-01,\n",
       "         -2.1698e-01,  1.1441e+00, -4.9270e+00, -2.3565e-01, -1.5865e-01,\n",
       "         -6.1929e-01,  3.3609e-01,  3.8436e-01,  2.9483e-01, -3.6156e-01,\n",
       "         -8.0146e-01, -7.9442e-01, -3.5196e-01, -9.6193e-01, -2.5164e-02],\n",
       "        [ 2.6077e-01,  4.6211e-01, -2.0788e-03,  7.0206e-01,  4.0434e-01,\n",
       "         -7.2777e-02,  1.1673e+00, -1.0756e+00, -1.8100e-01,  1.9997e-01,\n",
       "         -7.6649e-02, -2.8095e-02, -5.8306e+00,  5.7891e-01, -6.2818e-01,\n",
       "          6.7286e-02, -8.3564e-02, -9.0315e-01,  4.0830e-01, -3.6265e-01,\n",
       "         -9.2463e-01,  3.1741e-01, -2.1676e-01, -1.0840e+00, -1.4597e+00],\n",
       "        [-1.8627e-01,  6.9592e-01,  5.8518e-01, -3.3887e-01,  8.1060e-01,\n",
       "          2.3211e-01,  1.0227e+00, -6.2124e-01, -4.2221e-01,  1.2852e-01,\n",
       "         -4.3517e-01, -2.5154e-01, -4.4831e+00, -2.1106e-01, -3.1913e-01,\n",
       "          5.3166e-02,  4.5791e-01, -5.3280e-01,  5.8542e-01,  4.8431e-02,\n",
       "          1.2931e-01,  9.8903e-02, -4.7996e-01, -7.7182e-01,  6.7855e-01],\n",
       "        [-3.7268e-01,  7.0825e-01,  3.1727e-01,  6.9056e-01, -3.2914e-03,\n",
       "          3.2840e-01,  1.4929e+00, -1.1979e+00, -5.4900e-01, -3.4809e-01,\n",
       "         -2.3858e-01,  2.7431e-01, -3.8364e+00, -2.8701e-01,  4.2168e-01,\n",
       "          5.6682e-01,  4.6106e-01,  3.8261e-01,  7.5994e-01, -6.9101e-01,\n",
       "         -4.1556e-01, -5.3662e-01, -9.1868e-01, -1.7186e-01, -8.0563e-01],\n",
       "        [-2.8653e-01,  6.0501e-01,  6.2592e-01, -3.4889e-02, -1.0508e-01,\n",
       "          6.3965e-02,  1.1527e+00, -1.8502e-01, -2.2128e-01,  2.9563e-01,\n",
       "         -6.1197e-02,  7.1973e-01, -5.4451e+00, -5.5855e-02,  7.8477e-02,\n",
       "         -9.0364e-03,  3.2605e-01, -9.0771e-01, -5.3689e-01, -3.4474e-01,\n",
       "         -3.7130e-01, -1.7721e-01,  8.7016e-01, -1.5274e-01,  2.6154e-02],\n",
       "        [ 5.5065e-01,  6.5401e-01, -1.9103e-02, -5.6375e-01, -5.8273e-01,\n",
       "          2.4631e-01,  1.4212e+00, -1.0809e+00, -4.6739e-01,  2.3774e-01,\n",
       "         -3.2032e-02,  5.3742e-01, -6.0165e+00, -6.5557e-02, -5.9013e-01,\n",
       "          5.2498e-01,  1.4897e-01, -8.3725e-01,  6.1225e-01, -6.8926e-01,\n",
       "          6.9384e-01,  6.7523e-01,  1.8845e-01, -1.2302e-01, -3.0455e-01],\n",
       "        [ 4.4205e-01, -6.7697e-01, -7.9938e-02,  8.9579e-01, -4.3245e-02,\n",
       "          3.5863e-01,  5.1735e-01,  1.4330e+00, -2.1658e-01,  9.3923e-01,\n",
       "          3.6207e-01, -2.7295e-01, -3.4128e+00,  4.6583e-01, -8.7769e-01,\n",
       "         -4.2464e-01, -1.3648e+00,  4.3996e-01, -2.4477e+00, -2.3733e-01,\n",
       "          4.2426e-01,  1.8637e-01, -1.9753e-01,  2.6109e-01,  4.4809e-01],\n",
       "        [ 4.4173e-01,  6.5815e-02, -2.0495e-01, -1.0438e+00, -1.2233e-01,\n",
       "          8.1669e-01, -2.5311e-01,  2.0114e+00, -6.5853e-01, -8.6599e-01,\n",
       "          1.5305e-01, -1.5383e+00, -2.7010e+00, -8.1569e-01,  9.7446e-01,\n",
       "          9.0630e-01,  8.3168e-01, -2.9246e-01,  8.2293e-03,  1.8712e-01,\n",
       "          7.5046e-01,  1.7449e-01,  1.2293e+00,  9.0675e-01, -3.4519e-01],\n",
       "        [ 3.8439e-01,  1.6041e-01, -3.4740e-01, -2.9171e-01, -6.0481e-01,\n",
       "         -2.9465e-01, -3.2613e-01, -1.9209e+00,  3.1216e-01, -1.2195e-02,\n",
       "          1.8807e-02,  4.2426e-01, -6.9904e-01, -1.2395e-01,  2.4919e-01,\n",
       "          2.0626e-01, -7.3372e-01, -3.0995e-01,  1.6759e+00,  4.7167e-02,\n",
       "          5.3861e-01,  1.2362e+00, -6.1563e-01, -1.7350e+00, -1.0748e-01],\n",
       "        [ 6.9586e-01, -1.1469e+00, -4.1797e-01, -2.2311e-02, -2.3801e-02,\n",
       "          8.2358e-01,  1.2228e+00,  1.7410e+00, -9.0979e-01,  1.3725e+00,\n",
       "          1.1530e-01, -6.3906e-01, -3.2252e+00,  6.1269e-01,  3.3544e-01,\n",
       "         -5.7058e-01, -5.0861e-01, -1.6575e-01, -9.8153e-01, -8.2130e-01,\n",
       "          2.4333e-01, -1.4482e-01, -6.7877e-01,  7.0610e-01,  4.0833e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec  = GloVe(\"twitter.27B\",dim=25)\n",
    "vec.get_vecs_by_tokens(tonkenized_df.iloc[4][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 50\n",
    "def getvec(tensor, length):\n",
    "    if tensor.size()[0] > length:\n",
    "        return tensor[0:length,:]\n",
    "    m = nn.ZeroPad2d((0, 0, length-tensor.size()[0], 0))\n",
    "    return m(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.7283, -1.6362, -1.7241,  ...,  0.5071, -0.8709, -0.8151],\n",
      "         [-0.4473, -0.8417,  0.4949,  ...,  0.5016, -0.7426, -0.1845],\n",
      "         [ 0.6153,  0.4090, -0.3422,  ..., -0.4323, -0.9998, -0.6808]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.7283, -1.6362, -1.7241,  ...,  0.5071, -0.8709, -0.8151],\n",
      "         [-0.4473, -0.8417,  0.4949,  ...,  0.5016, -0.7426, -0.1845],\n",
      "         [ 0.6153,  0.4090, -0.3422,  ..., -0.4323, -0.9998, -0.6808]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.8122, -0.2860,  0.0625,  ..., -0.3610, -0.0500, -0.7247],\n",
      "         [-0.0102,  0.0202,  0.2147,  ...,  0.1878, -0.8425, -0.3121],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.8900, -0.3419,  0.6922,  ..., -0.8791,  0.2372, -0.7153],\n",
      "         [-0.2667,  0.9578,  0.8541,  ...,  0.3787,  0.7867, -0.0205],\n",
      "         [ 0.6959, -1.1469, -0.4180,  ..., -0.6788,  0.7061,  0.4083]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.2823,  0.0196,  0.1151,  ...,  0.2143,  0.2542, -0.2667],\n",
      "         [-0.7787,  0.7259,  0.3502,  ...,  0.3649,  0.2566,  0.2777],\n",
      "         [ 1.1040, -0.3463,  0.0888,  ..., -1.1142,  1.3360,  0.2015]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1824,  0.7053, -0.3421,  ...,  0.3131,  0.0879, -0.8868],\n",
      "         [ 0.5507,  0.6540, -0.0191,  ...,  0.1884, -0.1230, -0.3045],\n",
      "         ...,\n",
      "         [-0.0102,  0.0202,  0.2147,  ...,  0.1878, -0.8425, -0.3121],\n",
      "         [ 0.5911,  0.3876, -1.1486,  ..., -0.2388, -0.0189, -0.1481],\n",
      "         [ 0.6959, -1.1469, -0.4180,  ..., -0.6788,  0.7061,  0.4083]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.zeros(len(df),length,25)\n",
    "\n",
    "for index , row in df.iterrows(): \n",
    "    ret = vec.get_vecs_by_tokens(tonkenized_df.iloc[index][\"text\"], lower_case_backup=True)\n",
    "    ret = getvec(ret, 50)\n",
    "    X[index, :,:] = ret\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28126, 50, 25])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor(tonkenized_df[\"classification\"].astype(np.float32)).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=49)\n",
    "X_test, X_train = X_test.to(device), X_train.to(device)\n",
    "y_test, y_train = y_test.to(device), y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_rnnlayers, num_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_rnnlayers = num_rnnlayers\n",
    "        self.num_outputs = num_outputs\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.num_inputs,\n",
    "            hidden_size=self.num_hidden,\n",
    "            num_layers=self.num_rnnlayers,\n",
    "            batch_first=True)\n",
    "        self.fc = nn.Linear(self.num_hidden, self.num_outputs)\n",
    "    def forward(self,X): \n",
    "        h0 = torch.zeros(self.num_rnnlayers, X.size(0),\n",
    "                         self.num_hidden,device = device)\n",
    "        c0 = torch.zeros(self.num_rnnlayers, X.size(0),\n",
    "                         self.num_hidden,device = device)\n",
    "        out, _ = self.rnn(X, (h0, c0))\n",
    "        out, _ = torch.max(out, 1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_inputs=25, num_hidden=50, num_rnnlayers=2, num_outputs=1)\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42400\\1606023136.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss_train_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "num_epochs = 3000 #model overfits after 3000 epochs\n",
    "loss_train_list = np.zeros(num_epochs)\n",
    "loss_test_list = np.zeros(num_epochs)\n",
    "acc_train_list = np.zeros(num_epochs)\n",
    "acc_test_list = np.zeros(num_epochs)\n",
    "for i in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_result = model(X_train)\n",
    "    loss_train = criterion(y_result,y_train)\n",
    "    loss_train_list[i] = loss_train.item()\n",
    "\n",
    "    train_acc = np.mean(np.round(y_result.cpu().detach().numpy()) == np.round(y_train.cpu().detach().numpy()))\n",
    "    acc_train_list[i] = train_acc\n",
    "    \n",
    "    y_result = model(X_test)\n",
    "    loss_test = criterion(y_result,y_test)\n",
    "    loss_test_list[i] = loss_test.item()\n",
    "    \n",
    "    test_acc = np.mean(np.round(y_result.cpu().detach().numpy()) == np.round(y_test.cpu().detach().numpy()))\n",
    "    acc_test_list[i] = test_acc\n",
    "\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "plt.plot(loss_train_list, label = \"loss_train_list\")\n",
    "plt.plot(loss_test_list, label = \"loss_test_list\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9820c6239cdbb7db630939f5e05a5bf32e3e26a5f6ce0089fd4cbdc93b6da2ff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('stonk': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
