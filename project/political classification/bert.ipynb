{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_finalized.csv\",index_col=0)\n",
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12021</th>\n",
       "      <td>The 'in'justice system in the U.S. is broken. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>Alright, a bunch of things for me to unpack:</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23929</th>\n",
       "      <td>Anyone else think you could blindfold Morning ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27413</th>\n",
       "      <td>\"Did You Not Prepare for This Hearing?\" - Sen....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>No one but the completely bought in are believ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25508</th>\n",
       "      <td>Sit her fat stinky ass in front of a TV and ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>Biden is, just getting the due diligence part ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>A sitting President has never lost an election...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>Should be everyone’s religion in a country tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>No, because that would require reading and com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14063 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  classification\n",
       "12021  The 'in'justice system in the U.S. is broken. ...               0\n",
       "4132        Alright, a bunch of things for me to unpack:               0\n",
       "23929  Anyone else think you could blindfold Morning ...               1\n",
       "27413  \"Did You Not Prepare for This Hearing?\" - Sen....               1\n",
       "8566   No one but the completely bought in are believ...               0\n",
       "...                                                  ...             ...\n",
       "25508  Sit her fat stinky ass in front of a TV and ha...               1\n",
       "6173   Biden is, just getting the due diligence part ...               0\n",
       "14800  A sitting President has never lost an election...               1\n",
       "2775   Should be everyone’s religion in a country tha...               0\n",
       "2745   No, because that would require reading and com...               0\n",
       "\n",
       "[14063 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[0:14063, :]\n",
    "df['classification'] = df['classification'].map({'left': 0, 'right': 1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\Thanat M/.cache\\huggingface\\transformers\\45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Thanat M/.cache\\huggingface\\transformers\\c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\Thanat M/.cache\\huggingface\\transformers\\534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Thanat M/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Thanat M/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Thanat M/.cache\\huggingface\\transformers\\a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df[\"text\"])\n",
    "y = list(df[\"classification\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n",
    "X_train_tokenized = tokenizer(X_train, padding = True, truncation = True, max_length = 50)\n",
    "X_val_tokenized = tokenizer(X_val, padding = True, truncation = True, max_length = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    seed=0,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanat M\\.conda\\envs\\stonk\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11250\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4221\n",
      " 12%|█▏        | 500/4221 [00:44<05:30, 11.26it/s]***** Running Evaluation *****\n",
      "  Num examples = 2813\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6318, 'learning_rate': 4.4077232883203036e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 12%|█▏        | 500/4221 [00:49<05:30, 11.26it/s]Saving model checkpoint to output\\checkpoint-500\n",
      "Configuration saved in output\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5871461629867554, 'eval_accuracy': 0.6892996800568788, 'eval_precision': 0.6685934489402697, 'eval_recall': 0.7441029306647605, 'eval_f1': 0.7043301759133964, 'eval_runtime': 5.5852, 'eval_samples_per_second': 503.654, 'eval_steps_per_second': 63.024, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-500\\pytorch_model.bin\n",
      " 24%|██▎       | 1000/4221 [01:36<04:48, 11.18it/s] ***** Running Evaluation *****\n",
      "  Num examples = 2813\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6083, 'learning_rate': 3.815446576640607e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 24%|██▎       | 1000/4221 [01:41<04:48, 11.18it/s]Saving model checkpoint to output\\checkpoint-1000\n",
      "Configuration saved in output\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6163279414176941, 'eval_accuracy': 0.6473515819409883, 'eval_precision': 0.8747697974217311, 'eval_recall': 0.33952823445318087, 'eval_f1': 0.4891864057672503, 'eval_runtime': 5.6414, 'eval_samples_per_second': 498.635, 'eval_steps_per_second': 62.396, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-1000\\pytorch_model.bin\n",
      " 36%|███▌      | 1500/4221 [02:28<04:06, 11.03it/s]  ***** Running Evaluation *****\n",
      "  Num examples = 2813\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.548, 'learning_rate': 3.2231698649609096e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 36%|███▌      | 1500/4221 [02:33<04:06, 11.03it/s]Saving model checkpoint to output\\checkpoint-1500\n",
      "Configuration saved in output\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5891557931900024, 'eval_accuracy': 0.7220049768929968, 'eval_precision': 0.7526617526617526, 'eval_recall': 0.6568977841315226, 'eval_f1': 0.7015267175572519, 'eval_runtime': 5.6681, 'eval_samples_per_second': 496.29, 'eval_steps_per_second': 62.102, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-1500\\pytorch_model.bin\n",
      " 47%|████▋     | 2000/4221 [03:20<03:17, 11.23it/s]***** Running Evaluation *****\n",
      "  Num examples = 2813\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4383, 'learning_rate': 2.630893153281213e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 47%|████▋     | 2000/4221 [03:26<03:17, 11.23it/s]Saving model checkpoint to output\\checkpoint-2000\n",
      "Configuration saved in output\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6324204802513123, 'eval_accuracy': 0.71240668325631, 'eval_precision': 0.6862373737373737, 'eval_recall': 0.7769835596854896, 'eval_f1': 0.728796513576936, 'eval_runtime': 5.6856, 'eval_samples_per_second': 494.761, 'eval_steps_per_second': 61.911, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-2000\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output\\checkpoint-500 (score: 0.5871461629867554).\n",
      " 47%|████▋     | 2000/4221 [03:32<03:55,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 212.1968, 'train_samples_per_second': 159.05, 'train_steps_per_second': 19.892, 'train_loss': 0.5566070022583007, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.5566070022583007, metrics={'train_runtime': 212.1968, 'train_samples_per_second': 159.05, 'train_steps_per_second': 19.892, 'train_loss': 0.5566070022583007, 'epoch': 1.42})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"dataset_finalized.csv\",index_col=0)\n",
    "df = df.sample(frac = 1)\n",
    "df['classification'] = df['classification'].map({'left': 0, 'right': 1})\n",
    "test_data = df.iloc[14063:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list(test_data[\"text\"])\n",
    "X_test_tokenized = tokenizer(X_test, padding = True, truncation = True, max_length = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset(X_test_tokenized)\n",
    "test_trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 14063\n",
      "  Batch size = 8\n",
      "100%|██████████| 1758/1758 [00:40<00:00, 66.67it/s]"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "raw_pred, _, _ = trainer.predict(test_dataset)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6974329801607054\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred == test_data[\"classification\"].to_numpy())\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "  \"\"\"\n",
    "  This function prints and plots the confusion matrix.\n",
    "  Normalization can be applied by setting `normalize=True`.\n",
    "  \"\"\"\n",
    "  if normalize:\n",
    "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "      print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "      print('Confusion matrix, without normalization')\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[4524 2510]\n",
      " [1745 5284]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_data[\"classification\"].to_numpy(), y_pred)\n",
    "plot_confusion_matrix(cm, [0,1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9820c6239cdbb7db630939f5e05a5bf32e3e26a5f6ce0089fd4cbdc93b6da2ff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('stonk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
